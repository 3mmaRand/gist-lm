[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"hex logo","code":""},{"path":"index.html","id":"who-is-this-book-for","chapter":"Welcome!","heading":"0.1 Who is this book for?","text":"done introductory data analysis course R? Yes? book might ! aimed non-specialists learned introductory data analysis skill research another field. readers mind writing book undergraduates degree programmes life sciences done introductory course data analysis R. introductory courses usually teach null hypothesis testing single linear regression, t-tests, ANOVA. might also find book useful done similar introductory data analysis course part social science, media, finance education degree programme. use examples life sciences require little general knowledge principles apply field.assume understanding rationale hypothesis testing experience selecting, applying interpreting tests. also assume familiarity R RStudio general, expert, proficiency summarising, analysing visualising data functions t.test(), aov(), TukeyHSD() ggplot(). assume fluency allows things without looking things !book starts overview typical introductory data analysis course. intend set scene, summarise expected background experience clarify terminology used rest book. coverage single linear regression first chapter Part 2 also likely revision readers.book two aims. First explain t-test, ANOVA regression actually test introduce terminology statistical modelling , secondly, teach use interpret lm() function.","code":""},{"path":"index.html","id":"approach-of-this-book","chapter":"Welcome!","heading":"0.2 Approach of this book","text":"Regression, t-tests one-way ANOVA special cases much widely applicable statistical model known “general linear model.” Since fundamentally test, can carried lm() function R. However, common t-tests ANOVA taught non-specialists using t.test() aov() functions respectively. sensible reasons . example, many introductory texts take approach typically, outputs t.test() aov() easier beginners understand interpret.However, output lm() typical statistical modelling functions general made harder understand used using lm() relatively simple cases. makes use slightly advanced methods seem like bigger leap understanding really , extending statistical repertoire intimidating . approach taken book exploit pre-existing knowledge t-tests ANOVA using t.test() aov() understand output lm().lm() can used perform t-tests, ANOVAs regression.Examples carried familiar functions lm() can make link two. example demonstrates R code needed, understand output report results, including suggested ggplot2 figures.\ncode given figures , isn’t book ggplot2, extensively explained. Readers keen learn ggplot2 advised go https://ggplot2.tidyverse.org/.","code":""},{"path":"index.html","id":"overview-of-the-chapter-contents","chapter":"Welcome!","heading":"0.3 Overview of the chapter contents","text":"Introduction provides brief overview typical introductory data analysis class using terminology used throughout remaining chapters. concepts chapter unfamiliar, may benefit revising previous work.Using lm() familiar tests revise single linear regression likely previously encountered lm() function. work example t-test first carried t.test() lm() gain good understanding lm() output. followed examples one- two-way ANOVA carried aov() lm().","code":""},{"path":"index.html","id":"conventions-used-in-the-book","chapter":"Welcome!","heading":"0.4 Conventions used in the book","text":"Code output appears blocks formatted like :Lines output start #.Within text:\n- packages indicated bold code font like : ggplot2\n- functions indicated code font brackets name like : ggplot()\n- R objects indicated code font like : stagKey points summarised throughout book using boxes like :key point previous paragraphs boxes like theseExtra pieces information essential understanding material presented like :Extra information tips boxes like ","code":"\nstag <- read_table(\"data-raw/stag.txt\")\nglimpse(stag)\n# Rows: 16\n# Columns: 2\n# $ jh   <dbl> 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 1~\n# $ mand <dbl> 0.56, 0.35, 0.28, 1.22, 0.48, 0.86, 0.68, 0.77, 0.55, 1.18, 0.71,~"},{"path":"index.html","id":"following-along-with-the-examples","chapter":"Welcome!","heading":"0.5 Following along with the examples","text":"Readers may wish code along following gives guidance best .recommend starting new RStudio project creating folder inside project called data-raw save data files. Links data files given text can downloaded data-raw folder right-clicking link choosing option save. make new script file example carry analysis example.example, call Project gist just started Chapter 4 Single linear regression, folder structure look like :Using structure mean paths files needed code given book.content code block can copied using icon top right corner.use packages tidyverse (Wickham et al. 2019) including ggplot2 (Wickham 2016), dplyr (Wickham et al. 2020), tidyr (Wickham 2020) readr (Wickham, Hester, Francois 2018) throughout book. code assumes loaded core tidyverse packages :run examples get error like :likely need load tidyverse shown .packages loaded explicitly library() statements needed.","code":"-- gist\n   |-- gist.Rproj\n   |-- stagbeetle_regresion.R\n   |-- data-raw\n      |-- stag.text\n\nlibrary(tidyverse)\n# Error in read_table(\"data-raw/stag.txt\") : \n#  could not find function \"read_table\""},{"path":"index.html","id":"credits","chapter":"Welcome!","heading":"Credits","text":"used bookdown package (Xie 2020) compile book. R session information shown :","code":"\nsessionInfo()\n# R version 4.1.0 (2021-05-18)\n# Platform: x86_64-w64-mingw32/x64 (64-bit)\n# Running under: Windows 10 x64 (build 18363)\n# \n# Matrix products: default\n# \n# locale:\n# [1] LC_COLLATE=English_United Kingdom.1252 \n# [2] LC_CTYPE=English_United Kingdom.1252   \n# [3] LC_MONETARY=English_United Kingdom.1252\n# [4] LC_NUMERIC=C                           \n# [5] LC_TIME=English_United Kingdom.1252    \n# \n# attached base packages:\n# [1] stats     graphics  grDevices utils     datasets  methods   base     \n# \n# other attached packages:\n#  [1] patchwork_1.1.1  kableExtra_1.3.4 forcats_0.5.1    stringr_1.4.0   \n#  [5] dplyr_1.0.7      purrr_0.3.4      readr_2.0.2      tidyr_1.1.4     \n#  [9] tibble_3.1.4     ggplot2_3.3.5    tidyverse_1.3.1 \n# \n# loaded via a namespace (and not attached):\n#  [1] Rcpp_1.0.7        svglite_2.0.0     lubridate_1.7.10  assertthat_0.2.1 \n#  [5] digest_0.6.28     utf8_1.2.2        R6_2.5.1          cellranger_1.1.0 \n#  [9] backports_1.2.1   reprex_2.0.1      evaluate_0.14     httr_1.4.2       \n# [13] pillar_1.6.3      rlang_0.4.11      readxl_1.3.1      rstudioapi_0.13  \n# [17] jquerylib_0.1.4   rmarkdown_2.11    webshot_0.5.2     munsell_0.5.0    \n# [21] broom_0.7.9       compiler_4.1.0    modelr_0.1.8      xfun_0.26        \n# [25] pkgconfig_2.0.3   systemfonts_1.0.2 htmltools_0.5.2   downlit_0.2.1    \n# [29] tidyselect_1.1.1  bookdown_0.24     fansi_0.5.0       viridisLite_0.4.0\n# [33] crayon_1.4.1      tzdb_0.1.2        dbplyr_2.1.1      withr_2.4.2      \n# [37] grid_4.1.0        jsonlite_1.7.2    gtable_0.3.0      lifecycle_1.0.1  \n# [41] DBI_1.1.1         magrittr_2.0.1    scales_1.1.1      cli_3.0.1        \n# [45] stringi_1.7.4     fs_1.5.0          xml2_1.3.2        bslib_0.3.0      \n# [49] ellipsis_0.3.2    generics_0.1.0    vctrs_0.3.8       tools_4.1.0      \n# [53] glue_1.4.2        hms_1.1.1         fastmap_1.1.0     yaml_2.2.1       \n# [57] colorspace_2.0-2  rvest_1.0.1       knitr_1.34        haven_2.4.3      \n# [61] sass_0.4.0"},{"path":"index.html","id":"license","chapter":"Welcome!","heading":"License","text":"online work licensed Creative Commons Attribution-ShareAlike 4.0 International.\nVisit information license.","code":""},{"path":"revision.html","id":"revision","chapter":"1 Revision of your Introductory class","heading":"1 Revision of your Introductory class","text":"experimental design execution manipulate, choose, one variables record effect manipulation another variable. variables manipulate called explanatory predictor variables called response. also known independent dependent variables respectively.Predictor, Explanatory, x Independent: terms used describe variables choose.Predicted, Response, y Dependent: terms used describe variable measure.plot data, response variable goes y-axis explanatory variable goes x-axis. two explanatory variables need another way visualise . Often might indicate different values second explanatory variable colour. third explanatory variable can displayed using different panels. See Figure 1.1.\nFigure 1.1: Explanatory variables placed x-axis , one, indicated different colours (shapes) panels. response variable always y-axis.\nchoosing regression, t-tests, one-way ANOVA two-way ANOVA consider many explanatory variables whether continuous categorical.one continuous explanatory variable can apply regression. explanatory variable categorical two groups (levels) choice t-test one-way ANOVA, two groups must use one-way ANOVA.two-way ANOVA used two categorical explanatory variables. See Figure 1.2.\nFigure 1.2: Decision tree choosing single linear regression, t-tests, one-way ANOVA two-way ANOVA.\napparently different tests , fact, test. underlying mathematics, put another way, follow model. model often known General Linear Model.","code":""},{"path":"what-are-linear-models.html","id":"what-are-linear-models","chapter":"2 What are General Linear Models","heading":"2 What are General Linear Models","text":"","code":""},{"path":"what-are-linear-models.html","id":"overview","chapter":"2 What are General Linear Models","heading":"2.1 Overview","text":"general linear model describes continuous response variable function one explanatory variables.\nsingle explanatory variable, model :\\[\\begin{equation}\nE(y_{})=\\beta_{0}+\\beta_{1}X1_{}\n\\tag{2.1}\n\\end{equation}\\]:\\(y\\) response variable \\(X1\\) explanatory variable.\\(\\) index values \\(X1_{}\\) \\(\\)th value \\(X1\\)\\(E(y_{})\\) expected value \\(y\\) \\(\\)th value \\(X1\\).\\(\\beta_{0}\\) \\(\\beta_{1}\\) coefficients - parameters - model. single linear regression, \\(\\beta_{0}\\) often called intercept \\(\\beta_{1}\\) slope.equation (2.1) allows response, \\(y\\), predicted given value explanatory variable.Let’s unpack mean \\(E(y_{})\\), expected value \\(y\\). measure response particular value \\(x\\) many times distribution responses. general linear model distribution assumed normal mean expected value \\(y\\), \\(E(y_{})\\).Another way saying general linear model, “model mean response.” measured response drawn normal distribution mean \\(E(y_{})\\) defining feature general linear model.additional assumption normal distributions variance \\(x\\) values.","code":""},{"path":"what-are-linear-models.html","id":"model-fitting","chapter":"2 What are General Linear Models","heading":"2.2 Model fitting","text":"process estimating model coefficients data (set chosen \\(X1\\) measured \\(y\\) values) known fitting linear model. coefficients also known parameters.measured response values data, \\(y_{}\\), differ predicted values, \\(\\hat{y}\\), randomly random differences known residuals errors. parameter values chosen minimise sum squared residuals. commonly used abbreviation sum squared residuals (errors) \\(SSE\\).\\[\\begin{equation}\nSSE = \\sum(y_{}-\\hat{y})^2\n\\tag{2.2}\n\\end{equation}\\]Since coefficient values minimise \\(SSE\\), values known least squares estimates. mean sample also least squares estimate -role played \\(SSE\\) estimating parameters means also used determining well model fits data. model can considered useful predictions close observed data smaller value \\(SSE\\), better fit. words, little random variance left response.\nabsolute value \\(SSE\\) depend size \\(y\\) values sample size difficult compare two models. Instead, express proportion total variation \\(y\\), \\(SST\\):\\[\\begin{equation}\nSSE / SST\n\\tag{2.3}\n\\end{equation}\\]proportion variance left model fitting. proportion variance explained model commonly used metric model fit probably heard - R-squared, \\(R^2\\). :\\[\\begin{equation}\nR^2=1-\\frac{SSE}{SST}\n\\tag{2.3}\n\\end{equation}\\]explanatory variables, value predict response variable mean. Thus good model fit response better mean. output lm() includes \\(R^2\\). represents proportional improvement predictions regression model relative mean model. ranges zero, model better mean, 1, predictions perfect. See Figure 2.1.\nFigure 2.1: linear model different fits. ) model poor fit - explanatory variable better response mean predicting response. B) model good fit - explanatory variable explains high proportion variance response. C) model perfect fit - response can predicted perfectly explanatory variable. Measured response values pink, predictions green dashed blue line gives mean response.\nSince distribution responses given \\(x\\) assumed normal variances distributions assumed homogeneous, also true residuals. examination residuals allows us evaluate whether assumptions met.See Figure 2.2 graphical representation linear modelling terms introduced far. reference figure later chapters.\nFigure 2.2: general linear model annotated terms used modelling. measured response values pink, predictions green, differences , known residuals, blue. estimated model parameters, \\(\\beta_{0}\\) (intercept) \\(\\beta_{1}\\) (slope) indicated.\n","code":""},{"path":"what-are-linear-models.html","id":"more-than-one-explanatory-variable","chapter":"2 What are General Linear Models","heading":"2.3 More than one explanatory variable","text":"one explanatory variable given \\(X2\\), \\(X3\\) \\(p\\)th explanatory variable. explanatory variable \\(\\beta\\) coefficient.general form model :\n\\[\\begin{equation}\nE(y_{})=\\beta_{0}+\\beta_{1}X1_{}+\\beta_{2}X2_{}+...+\\beta_{p}Xp_{}\n\\tag{2.4}\n\\end{equation}\\]model one intercept value response explanatory variables zero.one problem \\(R^2\\) measure model fit: explanatory variables added, higher \\(R^2\\). true even added variables explain really tiny amount variance response. Using \\(R^2\\) select model mean always choosing model variables .\nHowever, key aim statistical modelling understand response easier simpler models. want find balance complexity model explanatory power. Adjusted \\(R^2\\) way achieve . reduces \\(R^2\\) coefficient added.related reason including variables explain tiny amounts variance overfitting. Overfitting occurs model fits data well generalise. want models predict response equally well new set data.","code":""},{"path":"what-are-linear-models.html","id":"general-linear-models-in-r","chapter":"2 What are General Linear Models","heading":"2.4 General linear models in R","text":"","code":""},{"path":"what-are-linear-models.html","id":"building-and-viewing","chapter":"2 What are General Linear Models","heading":"2.4.1 Building and viewing","text":"T-tests ANOVA, like regression, can carried lm() function R. uses method specifying model. one explanatory variable command :lm(data = dataframe, response ~ explanatory)response ~ explanatory part known model formula.two explanatory variable add second explanatory variable formula using + *. command :lm(data = dataframe, response ~ explanatory1 + explanatory2)orlm(data = dataframe, response ~ explanatory1 * explanatory2)model explanatory1 + explanatory2 considers effects two variables independently. model explanatory1 * explanatory2 considers effects two variables interaction .usually assign output lm() commands object view summary(). typical workflow :\nmod <- lm(data = dataframe, response ~ explanatory)\nsummary(mod)\ntwo sorts statistical tests output summary(mod): tests whether coefficient significantly different zero; F-test model overall.F-test last line output indicates whether relationship modelled response set explanatory variables statistically significant.lm() can used perform tests using General Linear Model including t-tests, ANOVA regression response variables normally distributed.Elements lm() object include estimated coefficients, predicted values residuals. can accessed mod$coeffients, mod$fitted.values mod$residuals respectively.","code":""},{"path":"what-are-linear-models.html","id":"getting-predictions","chapter":"2 What are General Linear Models","heading":"2.4.2 Getting predictions","text":"mod$fitted.values gives predicted values explanatory variable values actually used experiment, .e., prediction row data. get predictions different set values need make dataframe different set values use predict() function. typical workflow :\npredict_for <- data.frame(explanatory = values)\npredict_for$pred <- predict(mod, newdata = predict_for)\n","code":""},{"path":"what-are-linear-models.html","id":"checking-assumptions","chapter":"2 What are General Linear Models","heading":"2.4.3 Checking assumptions","text":"assumptions model checked using plot() function produces diagnostic plots explore distribution residuals. proof assumptions met allow us quickly determine assumptions plausible, , assumptions violated data points contribute violation.two plots useful “Q-Q” plot (plot 2) “Residuals vs Fitted” plot (plot 1). given values argument plot().","code":""},{"path":"what-are-linear-models.html","id":"the-q-q-plot","chapter":"2 What are General Linear Models","heading":"2.4.3.1 The Q-Q plot","text":"Q-Q plot scatterplot residuals (standardised mean zero standard deviation 1) expected residuals normally distributed.points fall roughly line residuals normally distributed. example , residuals appear normally distributed.see patterns like find alternative general linear model non-parametric test generalised linear model. Sometimes, applying transformation response variable result better meeting assumptions.","code":"\nplot(mod, which = 2)"},{"path":"what-are-linear-models.html","id":"the-residuals-vs-fitted-plot","chapter":"2 What are General Linear Models","heading":"2.4.3.2 The Residuals vs Fitted plot","text":"Residuals vs Fitted plot shows residuals homogeneous variance non-linear patterns. Non-linear relationships explanatory variables response usually show plot model capture non-linear relationship. assumptions met, residuals equally spread around horizontal line :following two examples residuals homogeneous variance display non-linear patterns.\n","code":"\nplot(mod, which = 1)"},{"path":"what-are-linear-models.html","id":"reporting","chapter":"2 What are General Linear Models","heading":"2.5 Reporting","text":"important information include reporting results fitting linear model notable predictions significance, direction magnitude effects. need ensure reader understand data saying even numbers statistical information removed. example, \\(\\) much bigger \\(B\\) variable \\(Y\\) influenced variables \\(X1\\) (lot) \\(X2\\) (less ).\nrelatively simple models, reporting group means slope, statistical test information enough. complex models many variables common give estimated model coefficients table.addition, figure show data model. honest allows interpretation evaluated.","code":""},{"path":"terminolgy.html","id":"terminolgy","chapter":"3 Terminolgy","heading":"3 Terminolgy","text":"","code":""},{"path":"terminolgy.html","id":"general-generalised","chapter":"3 Terminolgy","heading":"3.1 General? Generalised?","text":"get started, need explain potentially confusing terminology. use term “general linear model” mean classical linear regression models continuous response variable explained one continuous categorical variables. include regression, t-tests, analysis variance (ANOVA) analysis covariance (ANCOVA). use term “generalised linear model” GLM refer larger class models formulated John Nelder Robert Wedderburn (1972) popularised “Generalized Linear Models,” influential book Peter McCullagh John Nelder (1989). models, response variable can follow number distributions including Poisson binomial distributions. texts, general linear model referred acronym GLM generalised linear model GLIM book use GLM refer generalised linear models .","code":""},{"path":"single-regression.html","id":"single-regression","chapter":"4 Single linear regression","heading":"4 Single linear regression","text":"probably one general linear model applied using lm() previously covered revision make clear links regression, t-tests ANOVA.","code":""},{"path":"single-regression.html","id":"introduction-to-the-example","chapter":"4 Single linear regression","heading":"4.1 Introduction to the example","text":"\nFigure 4.1: Male stag beetles Lucanus cervus, large mandibles resemble antlers stag give common scientific name (Cervus genus deer). Simon . Eugster - work, CC 3.0, https://commons.wikimedia.org/w/index.php?curid=7790887\nconcentration Juvenile growth hormone male stag beetles (Lucanus cervus) known influence mandible growth. See Figure 4.1Groups ten stag beetles treated different concentrations Juvenile growth hormone (pg\\(\\mu\\)l-1) average mandible size (mm) determined. data stag.txt. Juvenile hormone set experimenter expect mandible size normally distributed.2 variables: jh, concentration Juvenile growth hormone mand, average mandible size (mm) 10 stag beetlesWe import data read_table() function readr package plot ggplot() ggplot2 package. packages part tidyverse.Import data:Visualising data analysis sensible. case, help us determine relationship two variables linear.\nsimple scatter plot appropriate.","code":"\nstag <- read_table(\"data-raw/stag.txt\")\nggplot(data = stag, aes(x = jh, y = mand)) +\n        geom_point()"},{"path":"single-regression.html","id":"applying-and-interpreting-lm","chapter":"4 Single linear regression","heading":"4.2 Applying and interpreting lm()","text":"lm() function used build regression model:can read : fit linear model mandible size explained concentration Juvenile growth hormone.Printing mod console reveal estimated model parameters (coefficients) little else:\\(\\beta_{0}\\) labelled (Intercept) \\(\\beta_{1}\\) labelled jh. Thus, equation line :information, including statistical tests model parameters, obtained using summary():Coefficients table gives estimated \\(\\beta_{0}\\) \\(\\beta_{1}\\) along standard errors tests whether estimates differ zero. estimated value intercept 0.419 \\(\\pm\\) 0.139 differs significantly zero (\\(p\\) = 0.009). estimated value slope 0.006 \\(\\pm\\) 0.002, also differs significantly zero (\\(p\\) = 0.001).three lines bottom output give information fit model data. Multiple R-squared gives proportion variance response explained model. case, 0.543 variance mandible length explained model significant proportion variance (\\(p\\) = 0.001).p-value model p-value slope single linear regression , except intercept, one parameter (slope) model. Linear models form two-sample t-test also estimate just one parameter p-value also equal model p-value. case linear models.","code":"\nmod <- lm(data = stag, mand ~ jh)\nmod\n# \n# Call:\n# lm(formula = mand ~ jh, data = stag)\n# \n# Coefficients:\n# (Intercept)           jh  \n#     0.41934      0.00646\nsummary(mod)\n# \n# Call:\n# lm(formula = mand ~ jh, data = stag)\n# \n# Residuals:\n#     Min      1Q  Median      3Q     Max \n# -0.3860 -0.2028 -0.0975  0.1503  0.6069 \n# \n# Coefficients:\n#             Estimate Std. Error t value Pr(>|t|)   \n# (Intercept)  0.41934    0.13943    3.01   0.0094 **\n# jh           0.00646    0.00158    4.08   0.0011 **\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# \n# Residual standard error: 0.292 on 14 degrees of freedom\n# Multiple R-squared:  0.543,   Adjusted R-squared:  0.51 \n# F-statistic: 16.6 on 1 and 14 DF,  p-value: 0.00113"},{"path":"single-regression.html","id":"link-to-chapter-2.1","chapter":"4 Single linear regression","heading":"4.3 Link to Chapter 2.1","text":"estimated coefficients tell us mandible size predicted 0.419 Juvenile growth hormone zero increases 0.006 mm pg\\(\\mu\\)l-1 Juvenile growth hormone.Juvenile growth hormone 1 pg\\(\\mu\\)l-1 mandible predicted 0.419 + 0.006 = 0.426 mm.2 pg\\(\\mu\\)l-1 predicted mandible size 0.419 + 0.006 + 0.006 = 0.432 mm.general mandible size : \\(\\beta_{0}\\) + \\(x\\times\\beta_{0}\\) mm \\(x\\) pg\\(\\mu\\)l-1. See Figure 4.2 version Figure 2.2 annotated values example.\nFigure 4.2: model annotated values stag beetle example. measured response values pink, predictions green, residuals, blue. One example measured value, predicted value residual shown Juvenile hormone 130 pg\\(\\mu\\)l-1. estimated model parameters, \\(\\beta_{0}\\) \\(\\beta_{1}\\) indicated. Compare Figure 2.2.\n","code":""},{"path":"single-regression.html","id":"getting-predictions-from-the-model","chapter":"4 Single linear regression","heading":"4.4 Getting predictions from the model","text":"predict() function returns predicted values response. add column predicted values stag dataframe use:gives predictions actual Juvenile growth hormone concentration values used. want predictions values, need create data frame Juvenile growth hormone values want predict.\nfollowing creates dataframe one column Juvenile growth hormone values 0 150 steps 5:Note column named jh - dataset model. variable type must also match.predict responses new set explanatory variable values, name type explanatory variables new set must match model.get predicted mandible sizes Juvenile growth hormone values use:","code":"\nstag$pred <- predict(mod)\nglimpse(stag)\n# Rows: 16\n# Columns: 3\n# $ jh   <dbl> 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 1~\n# $ mand <dbl> 0.56, 0.35, 0.28, 1.22, 0.48, 0.86, 0.68, 0.77, 0.55, 1.18, 0.71,~\n# $ pred <dbl> 0.419, 0.484, 0.549, 0.613, 0.678, 0.742, 0.807, 0.871, 0.936, 1.~\npredict_for <- data.frame(jh = seq(0, 150, 5))\nglimpse(predict_for)\n# Rows: 31\n# Columns: 1\n# $ jh <dbl> 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 8~\npredict_for$pred <- predict(mod, newdata = predict_for)\nglimpse(predict_for)\n# Rows: 31\n# Columns: 2\n# $ jh   <dbl> 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80,~\n# $ pred <dbl> 0.419, 0.452, 0.484, 0.516, 0.549, 0.581, 0.613, 0.645, 0.678, 0.~"},{"path":"single-regression.html","id":"checking-assumptions-1","chapter":"4 Single linear regression","heading":"4.5 Checking assumptions","text":"two assumptions model can checked using diagnostic plots. Q-Q plot obtained :sample relatively small expect wiggliness saw 2.2 looks OK.Let’s look Residuals vs Fitted plot:red line wiggles little particular pattern appears variance homogeneous along mandible size.","code":"\nplot(mod, which = 2)\nplot(mod, which = 1)"},{"path":"single-regression.html","id":"creating-a-figure","chapter":"4 Single linear regression","heading":"4.6 Creating a figure","text":"suitable figure includes data model fitted:","code":"\nggplot(data = stag, aes(x = jh, y = mand)) +\n        geom_point() +\n        scale_x_continuous(expand = c(0.01, 0),\n                           limits = c(0, 160),\n                           name = expression(paste(\"Juvenile growth hormone (pg\",\n                                                   mu,\n                                                   l^-1,\n                                                   \")\"))) +\n        scale_y_continuous(expand = c(0, 0),\n                           limits = c(0, 2),\n                           name = \"Mandible length (mm)\") +\n        geom_smooth(method = lm, se = FALSE, colour = \"black\") +\n        theme_classic()"},{"path":"single-regression.html","id":"reporting-the-results","chapter":"4 Single linear regression","heading":"4.7 Reporting the results","text":"significant positive relationship concentration Juvenile growth hormone mandible length (\\(\\beta_{1}\\pm s.e.\\): 0.006 \\(\\pm\\) 0.002; \\(p\\) = 0.001). See figure 4.3.\nFigure 4.3: Relationship concentration Juvenile growth hormone mandible length.\n","code":""},{"path":"t-tests-revisit.html","id":"t-tests-revisit","chapter":"5 t-tests revisited","heading":"5 t-tests revisited","text":"chapter look example one categorical explanatory variable two groups (levels). first use familiar t.test() use output help us understand output lm(). also make predictions model report results.","code":""},{"path":"t-tests-revisit.html","id":"introduction-to-the-example-1","chapter":"5 t-tests revisited","heading":"5.1 Introduction to the example","text":"plant biotechnologists developed genetically modified line Cannabis sativa increase omega 3 fatty acids content. grew 50 wild type fifty modified plants maturity, collect seeds measure amount omega 3 fatty acids (arbitrary units). data csativa.txt. want know wild type modified plants differ significantly omega 3 fatty acid content.2 variables.\nplant explanatory variable; categorical 2 levels, modif wild.\nomega, continuous variable, response.use read_table() function import data visualise ggplot()quick plot data:Violin plots useful way show distribution data group way. One alternative geom_boxplot().modified plants lower mean omega 3 content wild type plants. modification appears successful! fact, may significantly lowered omega 3 content!Let’s create summary data useful plotting later:summary confirms see plot.Statistical comparison two means can done either t.test() lm() functions; exactly equivalent present results differently. use understanding applying interpreting t.test() develop understanding lm() output","code":"\ncsativa  <-  read_table(\"data-raw/csativa.txt\")\nggplot(data = csativa, aes(x = plant, y = omega)) +\n  geom_violin()\ncsativa_summary <- csativa %>%\n  group_by(plant) %>%\n  summarise(mean = mean(omega),\n            std = sd(omega),\n            n = length(omega),\n            se = std/sqrt(n))"},{"path":"t-tests-revisit.html","id":"t.test-output-reminder","chapter":"5 t-tests revisited","heading":"5.2 t.test() output reminder","text":"can apply two-sample t-test :two groups means given section labelled sample estimates test whether differ significantly given fourth line (beginning t = -5, df = ...). conclude mean omega 3 content modified plants (49.465 units) significantly lower wild type plants (\\(t\\) = 5.029, \\(d.f.\\) = 98, \\(p\\) < 0.001).line 95 percent confidence intervalgives confidence limits difference two means.sign \\(t\\) value confidence limits, order sample estimates given determined R’s alphabetical ordering groups. “modif” comes “wild” alphabet, “modif” first group. statistical test : modified plant mean \\(-\\) wild type mean.ordering arbitrary impact conclusions. wild type plants labelled “control” “modif” second group, output look like :conclusion remain : 49.465 significantly lower 56.412.t.test() output: estimates two group means p-value test difference .","code":"\nt.test(data = csativa, omega ~ plant, var.equal = TRUE)\n# \n#   Two Sample t-test\n# \n# data:  omega by plant\n# t = -5, df = 98, p-value = 0.000002\n# alternative hypothesis: true difference in means between group modif and group wild is not equal to 0\n# 95 percent confidence interval:\n#  -9.69 -4.21\n# sample estimates:\n# mean in group modif  mean in group wild \n#                49.5                56.4\n#   Two Sample t-test\n# \n# data:  omega by plant\n# t = 5.0289, df = 98, p-value = 2.231e-06\n# alternative hypothesis: true difference in means is not equal to 0\n# 95 percent confidence interval:\n#  4.205372 9.687828\n# sample estimates:\n# mean in group control  mean in group modif\n#             56.4118             49.4652\n# "},{"path":"t-tests-revisit.html","id":"t-tests-as-linear-models","chapter":"5 t-tests revisited","heading":"5.3 t-tests as linear models","text":"equation t-test just equation (2.1):\n\\[\\begin{equation}\nE(y_{})=\\beta_{0}+\\beta_{1}X1_{}\n\\tag{5.1}\n\\end{equation}\\]Remember, single linear regression \\(\\beta_{0}\\), intercept, value response numerical explanatory variable zero. mean explanatory variable categorical?means intercept value response categorical explanatory “lowest” level “lowest” level group comes first alphabetically.\\(X1_{}\\) indicator variable takes value 0 1 indicates whether \\(\\)th value one group . variables known dummy explanatory variables. dummy sense numerical substitutes categorical variable whose ‘real’ values names categories.can think \\(X1_{}\\) toggling \\(\\beta_{1}\\) effect:value 0 data point means \\(\\beta_{1}\\) impact response. response \\(\\beta_{0}\\).value 1 \\(\\beta_{1}\\) change response \\(\\beta_{0}\\) + \\(\\beta_{1}\\)\\(\\beta_{1}\\) thus difference group means.graphical representation terms linear model explanatory variable categorical two groups given Figure 5.1.\nFigure 5.1: linear model explanatory variable categorical two groups annotated terms used linear modelling. measured response values pink, predictions green, differences , known residuals, blue. estimated model parameters indicated: \\(\\beta_{0}\\) mean group \\(\\beta_{1}\\) added \\(\\beta_{0}\\) get mean group B. Compare Figure 2.2.\n","code":""},{"path":"t-tests-revisit.html","id":"applying-and-interpreting-lm-1","chapter":"5 t-tests revisited","heading":"5.4 Applying and interpreting lm()","text":"lm() function applied example follows:can read : fit linear model omega content explained plant type. Notice model formula t.test() lm() functions.Printing mod console gives us estimated model parameters (coefficients):first group plant modif \\(\\beta_{0}\\) mean modified plants. \\(\\beta_{1}\\) coefficient labelled plantwild. R, coefficients consistently named like : variable name followed value without spaces. means variable plant takes value wild, \\(\\beta_{1}\\) must added \\(\\beta_{0}\\)Thus, mean omega 3 modified plants 49.465 units wild type plants 49.465 + 6.947 = 56.412 units.information including statistical tests model parameters obtained using summary():Coefficients table gives estimated \\(\\beta_{0}\\) \\(\\beta_{1}\\) along standard errors tests whether estimates differ zero. estimated mean modified plants 49.465 \\(\\pm\\) 0.977 differs significantly zero (\\(p\\) < 0.001). estimated difference modified wild type plants 6.947 \\(\\pm\\) 1.381 also differs significantly zero (\\(p\\) < 0.001). fact value positive tells us wild type plants higher mean.proportion variance omega explained model 0.205 significant proportion variance (\\(p\\) < 0.001).true single linear regression, p-value model p-value difference means one parameter model intercept.Replacing terms shown Figure 5.1 values example gives us 5.2.\nFigure 5.2: annotated model values Omega 3 content Cannabis sativa example. measured response values pink, predictions green, residuals, blue. One example measured value, predicted value residual shown wild type individual. estimated model parameters indicated: \\(\\beta_{0}\\), mean modified plants, 49.465 \\(\\beta_{1}\\) 6.947. Thus mean wildtype plants 49.465 + 6.947 = 56.412 units. Compare Figure 5.1.\n","code":"\nmod <- lm(data = csativa, omega ~ plant)\nmod\n# \n# Call:\n# lm(formula = omega ~ plant, data = csativa)\n# \n# Coefficients:\n# (Intercept)    plantwild  \n#       49.47         6.95\nsummary(mod)\n# \n# Call:\n# lm(formula = omega ~ plant, data = csativa)\n# \n# Residuals:\n#     Min      1Q  Median      3Q     Max \n# -15.872  -3.703  -0.964   4.460  16.918 \n# \n# Coefficients:\n#             Estimate Std. Error t value             Pr(>|t|)    \n# (Intercept)   49.465      0.977   50.64 < 0.0000000000000002 ***\n# plantwild      6.947      1.381    5.03            0.0000022 ***\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# \n# Residual standard error: 6.91 on 98 degrees of freedom\n# Multiple R-squared:  0.205,   Adjusted R-squared:  0.197 \n# F-statistic: 25.3 on 1 and 98 DF,  p-value: 0.00000223"},{"path":"t-tests-revisit.html","id":"getting-predictions-from-the-model-1","chapter":"5 t-tests revisited","heading":"5.5 Getting predictions from the model","text":"already predictions possible values explanatory variable two!However code using predict included make easier understand complex examples later. need create dataframe values want predictions pass argument predict() function.create dataframe one column Plant values:Remember! variable values exactly match model.get predicted omega content two plant types:","code":"\npredict_for <- data.frame(plant = c(\"modif\", \"wild\"))\npredict_for$pred <- predict(mod, newdata = predict_for)\nglimpse(predict_for)\n# Rows: 2\n# Columns: 2\n# $ plant <chr> \"modif\", \"wild\"\n# $ pred  <dbl> 49.5, 56.4"},{"path":"t-tests-revisit.html","id":"checking-assumptions-2","chapter":"5 t-tests revisited","heading":"5.6 Checking assumptions","text":"two assumptions model can checked using diagnostic plots. Q-Q plot obtained :residual seem normally distributed.Let’s look Residuals vs Fitted plot:get two columns points explanatory variable, plant, categorical fitted - predicted - values just two means. view, variance looks higher group higher mean (right).","code":"\nplot(mod, which = 2)\nplot(mod, which = 1)"},{"path":"t-tests-revisit.html","id":"creating-a-figure-1","chapter":"5 t-tests revisited","heading":"5.7 Creating a figure","text":"","code":"\n#summarise the data \n\nggplot() +\n  geom_jitter(data = csativa, \n              aes(x = plant, y = omega), \n              width = 0.25, colour = \"grey\") +\n  geom_errorbar(data = csativa_summary,\n                aes(x = plant,\n                    ymin = mean,\n                    ymax = mean),\n                width = .3) +\n  geom_errorbar(data = csativa_summary,\n                aes(x = plant,\n                    ymin = mean - se,\n                    ymax = mean + se),\n                width = .5) +\n  geom_segment(aes(x = 1, y = 75, xend = 2, yend = 75),\n               size = 1) +\n  geom_segment(aes(x = 1, y = 75, xend = 1, yend = 73),\n               size = 1) +\n  geom_segment(aes(x = 2, y = 75, xend = 2, yend = 73),\n               size = 1) +\n  annotate(\"text\", x = 1.5, y = 77,  label = \"***\", size = 6) +\n  scale_x_discrete(labels = c(\"Modified\", \"Wild Type\"),\n                   name = \"Plant type\") +\n  scale_y_continuous(name = \"Amount of Omega 3 (units)\",\n                     expand = c(0, 0),\n                     limits = c(0, 90)) +\n  theme_classic()"},{"path":"t-tests-revisit.html","id":"reporting-the-results-1","chapter":"5 t-tests revisited","heading":"5.8 Reporting the results","text":"genetic modification unsuccessful wild type plants (\\(\\bar{x} \\pm s.e.\\): 56.412 \\(\\pm\\) 1.11 units) significantly higher omega 3 modified plants(49.465 \\(\\pm\\) 0.823 units) (\\(t\\) = 5.029; \\(d.f.\\) = 98; \\(p\\) < 0.001). See figure 5.3.\nFigure 5.3: Mean Omega 3 content wild type genetically modified Cannabis sativa. Error bars \\(\\pm 1 S.E.\\). *** significant difference \\(p < 0.001\\) level.\n","code":""},{"path":"one-way-anova-revisit.html","id":"one-way-anova-revisit","chapter":"6 One-way ANOVA revisited","heading":"6 One-way ANOVA revisited","text":"chapter consider example one categorical explanatory variable. However, time two groups (levels). first use familiar aov() function carry one-way ANOVA use understanding help us understand output lm(). also make predictions model report results.","code":""},{"path":"one-way-anova-revisit.html","id":"introduction-to-the-example-2","chapter":"6 One-way ANOVA revisited","heading":"6.1 Introduction to the example","text":"\nFigure 6.1: Baby Weddell Seals cute. Photo © Samuel Blanc, CC -SA 3.0, https://commons.wikimedia.org/w/index.php?curid=3877642\nmyoglobin concentration skeletal muscle (grams per kilogram muscle) three species seal (see Figure 6.1) given seal.txt.data collected determine whether muscle myoglobin differed species.2 variables.\nseal explanatory variable; categorical 3 levels, Bladdernose Seal, Harbour Seal Weddell Seal.\nmyoglobin, continuous variable, response.can use read_delim() function import data visualise ggplot().Let’s create summary data useful plotting later:summary confirms thirty individuals species highest mean Harbour Seals lowest Bladdernose Seals. variance within species similar.","code":"\nseal <- read_delim(\"data-raw/seal.txt\", delim = \" \")\n# create a rough plot of the data  \nggplot(data = seal, aes(x = species, y = myoglobin)) +\n  geom_violin()\nseal_summary <- seal %>%\n  group_by(species) %>%\n  summarise(mean = mean(myoglobin),\n            std = sd(myoglobin),\n            n = length(myoglobin),\n            se = std/sqrt(n))"},{"path":"one-way-anova-revisit.html","id":"aov-output-reminder","chapter":"6 One-way ANOVA revisited","heading":"6.2 aov() output reminder","text":"aov() function requires model formula, myoglobin ~ species, familiar format. also specify data argument indicate species myoglobin variables can found:output summary() function gives us ANOVA test:significant difference myoglobin concentration seal species (ANOVA: \\(F\\) = 5.352; \\(d.f.\\) = 2, 87; \\(p\\) = 0.006). need post-hoc multiple comparison test discover pairs means differ significantly.","code":"\nmod <- aov(data = seal, myoglobin ~ species)\nsummary(mod)\n#             Df Sum Sq Mean Sq F value Pr(>F)   \n# species      2    692     346    5.35 0.0064 **\n# Residuals   87   5627      65                  \n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"one-way-anova-revisit.html","id":"post-hoc-testing-for-aov","chapter":"6 One-way ANOVA revisited","heading":"6.3 Post-hoc testing for aov()","text":"commonly applied multiple comparison test applied significant ANOVA result Tukey Honest Significant Difference test:p-value, adjusted multiple comparisons given p adj column. case, one three pairwise comparisons significant. Harbour Seals, highest myoglobin concentrations (\\(\\bar{x} \\pm s.e.\\): 49.01 \\(\\pm\\) 1.507) ) significantly higher Bladdernose Seals lowest (\\(\\bar{x} \\pm s.e.\\): 42.316 \\(\\pm\\) 1.464).comparisons made known contrasts terminology appear later.","code":"\nTukeyHSD(mod)\n#   Tukey multiple comparisons of means\n#     95% family-wise confidence level\n# \n# Fit: aov(formula = myoglobin ~ species, data = seal)\n# \n# $species\n#                                diff   lwr    upr p adj\n# Harbour Seal-Bladdernose Seal  6.69  1.74 11.646 0.005\n# Weddell Seal-Bladdernose Seal  2.34 -2.61  7.296 0.499\n# Weddell Seal-Harbour Seal     -4.35 -9.30  0.602 0.097"},{"path":"one-way-anova-revisit.html","id":"one-way-anovas-as-linear-models","chapter":"6 One-way ANOVA revisited","heading":"6.4 One-way ANOVAs as linear models","text":"equation one-way ANOVA test extension equation (5.1) t-test. form additional parameters. three groups, model :\\[\\begin{equation}\nE(y_{})=\\beta_{0}+\\beta_{1}X1_{}+\\beta_{2}X2_{}\n\\tag{6.1}\n\\end{equation}\\]parameter \\(\\beta_{0}\\), intercept, value response categorical explanatory “lowest” level. \\(X1_{}\\) \\(X2_{}\\) dummy explanatory variables take value 0 1 toggle effects \\(\\beta_{1}\\) \\(\\beta_{2}\\) respectively.\\(\\beta_{1}\\) difference mean group represented intercept next group \\(\\beta_{2}\\) difference mean group represented intercept group .additional parameter dummy variable added additional group four groups equation :\\[\\begin{equation}\nE(y_{})=\\beta_{0}+\\beta_{1}X1_{}+\\beta_{2}X2_{}+\\beta_{3}X3_{}\n\\tag{6.2}\n\\end{equation}\\]graphical representation terms linear model explanatory variable categorical four groups given Figure 6.2.\nFigure 6.2: linear model explanatory variable categorical four groups annotated terms used linear modelling. measured response values pink, predictions green, differences , known residuals, blue. estimated model parameters indicated: \\(\\beta_{0}\\) mean group ; \\(\\beta_{1}\\) added \\(\\beta_{0}\\) get mean group B; \\(\\beta_{2}\\) added \\(\\beta_{0}\\) get mean group C; \\(\\beta_{3}\\) added \\(\\beta_{0}\\) get mean group D. figure, \\(\\beta_{1}\\) \\(\\beta_{2}\\) positive \\(\\beta_{3}\\) negative. Compare Figure 2.2.\n\\(\\beta\\) values given relative \\(\\beta_{0}\\). sign indicates whether group mean bigger (positive) smaller (negative) intercept.","code":""},{"path":"one-way-anova-revisit.html","id":"applying-and-interpreting-lm-2","chapter":"6 One-way ANOVA revisited","heading":"6.5 Applying and interpreting lm()","text":"lm() function applied seal example follows:Printing mod console gives us estimated model parameters (coefficients):first group seal Bladdernose Seal \\(\\beta_{0}\\) mean Bladdernose seals. \\(\\beta_{1}\\) coefficient labelled speciesHarbour Seal means variable species takes value Harbour Seal, \\(\\beta_{1}\\) must added \\(\\beta_{0}\\). last parameter, \\(\\beta_{2}\\), coefficient labelled speciesWeddell Seal means variable species takes value Weddell Seal, \\(\\beta_{2}\\) must added \\(\\beta_{0}\\).Bladdernose mean \\(\\beta_{0}\\)Harbour mean \\(\\beta_{0} + \\beta_{1}\\)Weddell mean \\(\\beta_{0} + \\beta_{2}\\)mean myoglobin Bladdernose seals 42.316 kg g-1, Harbour Seals 42.316 + 6.694 = 49.01 kg g-1 Weddell Seals 42.316 + 2.344 = 44.66kg g-1.information including statistical tests model parameters obtained using summary():Coefficients table gives estimated \\(\\beta_{0}\\), \\(\\beta_{1}\\) \\(\\beta_{2}\\) along standard errors tests whether estimates differ zero. estimated mean Bladdernose seals 42.316 \\(\\pm\\) 1.468 kg g1 differs significantly zero (\\(p\\) < 0.001). estimated difference Bladdernose Harbour seals 6.694 \\(\\pm\\) 2.077 also differs significantly zero (\\(p\\) = 0.002). estimated difference Bladdernose Weddell seals, 2.344 \\(\\pm\\) 2.077 kg g1, differ significantly zero (\\(p\\) = 0.262). fact parameters positive tells us two species higher means Bladdernose.proportion variance omega explained model 0.11 significant proportion variance (\\(p\\) = 0.006).first time model p-value model p-values \\(\\beta\\) parameters differ. fitting two parameters intercept.Replacing terms shown Figure 6.2 values example gives us 6.3.\nFigure 6.3: annotated model values Seal species example. measured response values pink, predictions green, residuals, blue. One example measured value, predicted value residual shown individual harbour seal. estimated model parameters indicated: \\(\\beta_{0}\\), mean Bladdernose Seals, 42.316 kg g1; \\(\\beta_{1}\\) 6.694 thus mean Harbour Seals 42.316 + 6.694 = 49.01 kg g^-1; \\(\\beta_{2}\\) 2.344 thus mean Weddell Seals 42.316 + 2.344 = 49.01 kg g^-1. Compare Figure 6.2.\n","code":"\nmod <- lm(data = seal, myoglobin ~ species)\nmod\n# \n# Call:\n# lm(formula = myoglobin ~ species, data = seal)\n# \n# Coefficients:\n#         (Intercept)  speciesHarbour Seal  speciesWeddell Seal  \n#               42.32                 6.69                 2.34\nsummary(mod)\n# \n# Call:\n# lm(formula = myoglobin ~ species, data = seal)\n# \n# Residuals:\n#     Min      1Q  Median      3Q     Max \n# -16.306  -5.578  -0.036   5.240  18.250 \n# \n# Coefficients:\n#                     Estimate Std. Error t value            Pr(>|t|)    \n# (Intercept)            42.32       1.47   28.82 <0.0000000000000002 ***\n# speciesHarbour Seal     6.69       2.08    3.22              0.0018 ** \n# speciesWeddell Seal     2.34       2.08    1.13              0.2620    \n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# \n# Residual standard error: 8.04 on 87 degrees of freedom\n# Multiple R-squared:  0.11,    Adjusted R-squared:  0.0891 \n# F-statistic: 5.35 on 2 and 87 DF,  p-value: 0.00643"},{"path":"one-way-anova-revisit.html","id":"getting-predictions-from-the-model-2","chapter":"6 One-way ANOVA revisited","heading":"6.6 Getting predictions from the model","text":"already predictions possible values explanatory variable categorical.However, code using predict included , last chapter, make easier understand complex examples later. need create dataframe values want predictions pass argument predict() function.create dataframe one column Species values:Remember! variable values exactly match model.get predicted myoglobin content three species:","code":"\npredict_for <- data.frame(species = c(\"Bladdernose Seal\",\n                                      \"Harbour Seal\",\n                                      \"Weddell Seal\"))\npredict_for$pred <- predict(mod, newdata = predict_for)"},{"path":"one-way-anova-revisit.html","id":"checking-assumptions-3","chapter":"6 One-way ANOVA revisited","heading":"6.7 Checking assumptions","text":"two assumptions model can checked using diagnostic plots. Q-Q plot obtained :Let’s look Residuals vs Fitted plot:residuals equally spread around horizontal line; assumptions seem met.","code":"\nplot(mod, which = 2)\nplot(mod, which = 1)"},{"path":"one-way-anova-revisit.html","id":"post-hoc-testing-for-lm","chapter":"6 One-way ANOVA revisited","heading":"6.8 Post-hoc testing for lm()","text":"TukeyHSD() requires output aov() use lsmeans() (Least-Squares means) function lsmeans package (Lenth 2016) pairs() multcompView package. two functions can applied lm() glm() outputs.Load packages:run post-hoc test:correction multiple testing uses Tukey method (just like TukeyHSD()).results using TukeyHSD() done tests using different function.","code":"\nlibrary(lsmeans)\nlibrary(multcompView)\nlsmeans(mod, ~ species) %>%\n  pairs()\n#  contrast                        estimate   SE df t.ratio p.value\n#  Bladdernose Seal - Harbour Seal    -6.69 2.08 87  -3.220  0.0050\n#  Bladdernose Seal - Weddell Seal    -2.34 2.08 87  -1.130  0.4990\n#  Harbour Seal - Weddell Seal         4.35 2.08 87   2.090  0.0970\n# \n# P value adjustment: tukey method for comparing a family of 3 estimates"},{"path":"one-way-anova-revisit.html","id":"creating-a-figure-2","chapter":"6 One-way ANOVA revisited","heading":"6.9 Creating a figure","text":"","code":"\nggplot() +\n  geom_jitter(data = seal, \n              aes(x = species, y = myoglobin), \n              width = 0.25, colour = \"grey\") +\n  geom_errorbar(data = seal_summary,\n                aes(x = species,\n                    ymin = mean,\n                    ymax = mean),\n                width = .3) +\n  geom_errorbar(data = seal_summary,\n                aes(x = species,\n                    ymin = mean - se,\n                    ymax = mean + se),\n                width = .5) +\n  geom_segment(aes(x = 1, y = 71, xend = 3, yend = 71),\n               size = 1) +\n  geom_segment(aes(x = 1, y = 71, xend = 1, yend = 69),\n               size = 1) +\n  geom_segment(aes(x = 3, y = 71, xend = 3, yend = 69),\n               size = 1) +\n  annotate(\"text\", x = 2, y = 73,  label = \"**\", size = 6) +\n  scale_x_discrete(name = \"Species\") +\n  scale_y_continuous(name = expression(\"Myoglobin concentration g \"*Kg^{-1}),\n                     expand = c(0, 0),\n                     limits = c(0, 75)) +\n  theme_classic()"},{"path":"one-way-anova-revisit.html","id":"reporting-the-results-2","chapter":"6 One-way ANOVA revisited","heading":"6.10 Reporting the results","text":"significant difference myoglobin concentration Seal species (ANOVA: \\(F\\) = 5.352; \\(d.f.\\) = 2, 87; \\(p\\) = 0.006). Post-hoc testing revealed difference Harbour Seal highest myoglobin concentrations (\\(\\bar{x} \\pm s.e.\\): 49.01 \\(\\pm\\) 1.507) ) Bladdernose Seal (\\(p\\) = 0.005) lowest (\\(\\bar{x} \\pm s.e.\\): 42.316 \\(\\pm\\) 1.464). See figure 6.4.\nFigure 6.4: Muscle myoglobin content three seal species. Error bars \\(\\pm 1 S.E.\\). ** significant difference \\(p < 0.001\\) level.\n","code":""},{"path":"two-way-anova-revisit.html","id":"two-way-anova-revisit","chapter":"7 Two-way ANOVA revisited","heading":"7 Two-way ANOVA revisited","text":"chapter turn attention designs two categorical explanatory variables. use approach used previous two chapters: first using familiar aov() function carry two-way ANOVA lm() function. also make predictions model report results.","code":""},{"path":"two-way-anova-revisit.html","id":"introduction-to-the-example-3","chapter":"7 Two-way ANOVA revisited","heading":"7.1 Introduction to the example","text":"Researchers collected live specimens two species periwinkle (see Figure 7.1) sites northern England Spring Summer. take measure gut parasite load examining slide gut contents. data periwinkle.txt.\nFigure 7.1: Periwinkles marine gastropod molluscs (slugs snails). ) Littorina brevicula (PD files - Public Domain, https://commons.wikimedia.org/w/index.php?curid=30577419) B) Littorina littorea. (photographed Guttorm Flatabø (user:dittaeva). - Photograph taken Olympus Camedia C-70 Zoom digital camera. Metainformation edited Irfanview, possibly cropped jpegcrop., CC -SA 3.0, https://commons.wikimedia.org/w/index.php?curid=324769\ndata collected determine whether effect season species parasite load whether effects independent.3 variables: species seasonare categorical explanatory variables, two levels;\npara, continuous variable, response.can use read_delim() function import data.visualising data ggplot() need account explanatory variables. can map one x-axis different aesthetic. Using fill aesthetic works well violin plots.\nParasite load seems higher species summer effect looks bigger L.brevicula - lowest spring mean highest summer mean.Let’s create summary data useful plotting later:summary confirms species higher mean summer difference species reversed - L.brevicula \\(-\\) L.littorea -7.28 spring 3.48 summer.","code":"\nperiwinkle <- read_delim(\"data-raw/periwinkle.txt\", delim = \"\\t\")\nggplot(data = periwinkle, aes(x = season, y = para, fill = species)) +\n  geom_violin()\nperi_summary <- periwinkle %>% \n  group_by(season, species) %>% \n  summarise(mean = mean(para),\n            sd = sd(para),\n            n = length(para),\n            se = sd / sqrt(n))"},{"path":"two-way-anova-revisit.html","id":"aov-output-reminder-1","chapter":"7 Two-way ANOVA revisited","heading":"7.2 aov() output reminder","text":"aov() function requires model formula includes explanatory variables interaction familiar format: para ~ season * season . also specify data argument indicate variables can found:output summary() function gives us ANOVA test:significantly greater number parasites Summer Spring (ANOVA: \\(F\\) = 25.58; \\(d.f.\\) = 1, 96; \\(p\\) < 0.001). difference species averaged across seasons significant interaction (ANOVA: \\(F\\) = 6.053; \\(d.f.\\) = 1, 96; \\(p\\) = 0.016) season species higher numbers infecting L.littorea Spring whilst L.brevicula heavily parasitized Summer.need post-hoc test discover comparisons significant.","code":"\nmod <- aov(data = periwinkle, para ~ season * species)\nsummary(mod)\n#                Df Sum Sq Mean Sq F value   Pr(>F)    \n# season          1   3058    3058   25.58 0.000002 ***\n# species         1     90      90    0.75    0.387    \n# season:species  1    724     724    6.05    0.016 *  \n# Residuals      96  11477     120                     \n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"two-way-anova-revisit.html","id":"post-hoc-testing-for-aov-1","chapter":"7 Two-way ANOVA revisited","heading":"7.3 Post-hoc testing for aov","text":"Tukey Honest Significant Difference test carried :parasite load L.brevicula increases significantly spring summer (\\(p\\) < 0.001) L.littorea . significant comparisons : spring load L.brevicula lower summer load L.littorea (\\(p\\) < 0.001); summer load L.brevicula higher spring load L.littorea (\\(p\\) = 0.02).","code":"\nTukeyHSD(mod)\n#   Tukey multiple comparisons of means\n#     95% family-wise confidence level\n# \n# Fit: aov(formula = para ~ season * species, data = periwinkle)\n# \n# $season\n#               diff  lwr  upr p adj\n# Summer-Spring 11.1 6.72 15.4     0\n# \n# $species\n#                                        diff   lwr  upr p adj\n# Littorina littorea-Littorina brevicula  1.9 -2.44 6.24 0.387\n# \n# $`season:species`\n#                                                        diff     lwr   upr p adj\n# Summer:Littorina brevicula-Spring:Littorina brevicula 16.44   8.354 24.53 0.000\n# Spring:Littorina littorea-Spring:Littorina brevicula   7.28  -0.806 15.37 0.093\n# Summer:Littorina littorea-Spring:Littorina brevicula  12.96   4.874 21.05 0.000\n# Spring:Littorina littorea-Summer:Littorina brevicula  -9.16 -17.246 -1.07 0.020\n# Summer:Littorina littorea-Summer:Littorina brevicula  -3.48 -11.566  4.61 0.675\n# Summer:Littorina littorea-Spring:Littorina littorea    5.68  -2.406 13.77 0.263"},{"path":"two-way-anova-revisit.html","id":"two-way-anovas-as-linear-models","chapter":"7 Two-way ANOVA revisited","heading":"7.4 Two-way ANOVAs as linear models","text":"equation two-way ANOVA test extension equation (6.1) one-way ANOVA test. form additional parameter. two groups explanatory variable, model :\\[\\begin{equation}\nE(y_{})=\\beta_{0}+\\beta_{1}X1_{}+\\beta_{2}X2_{}+\\beta_{3}X1_{}X2_{}\n\\tag{6.1}\n\\end{equation}\\]intercept, \\(\\beta_{0}\\) value response categorical explanatory variables “lowest” level. \\(X1_{}\\) dummy explanatory variable indicates first explanatory variable changing second level. toggles effects \\(\\beta_{1}\\). \\(X2_{}\\) dummy explanatory variable indicates second explanatory variable changing second level toggles effects \\(\\beta_{2}\\). \\(\\beta_{3}\\) interaction effect. \\(X1_{}\\) \\(X2_{}\\) 1 \\(\\beta_{3}\\) extra effect combination sum \n\\(\\beta_{1}+\\beta_{2}\\)Spring L.brevicula mean \\(\\beta_{0}\\)Summer L.brevicula mean \\(\\beta_{0} + \\beta_{1}\\)Spring L.littorea \\(\\beta_{0} + \\beta_{2}\\)Summer L.littorea \\(\\beta_{0} + \\beta_{3}\\)number parameters two-way ANOVA design : number levels one explanatory \\(\\times\\) number levels explanatory. explanatory three levels, nine \\(\\beta s\\)graphical representation terms linear model two explanatory variables two groups (levels) given Figure 7.2.\nFigure 7.2: linear model two explanatory variables two levels. ‘Variable 1’ levels ‘’ ‘B’ ‘Variable 2’ levels ‘’ ‘b.’ Thus 2 \\(\\times\\) 2 = 4 groups: Aa, Ab, Ba Bb. measured response values pink predictions green. residuals indicated. estimated model parameters indicated: \\(\\beta_{0}\\) mean group Aa; \\(\\beta_{1}\\) added \\(\\beta_{0}\\) get mean group Ab; \\(\\beta_{2}\\) added \\(\\beta_{0}\\) get mean group Ba; \\(\\beta_{3}\\) added \\(\\beta_{0}\\) addition \\(\\beta_{1}\\) \\(\\beta_{2}\\) get mean group Bb. figure, parameters positive. Compare Figure 2.2.\nintercept, \\(\\beta_{0}\\)response explanatory variable first group \\(\\beta s\\) given relative .interaction parameters give effect combination addition sum independent effects","code":""},{"path":"two-way-anova-revisit.html","id":"applying-and-interpreting-lm-3","chapter":"7 Two-way ANOVA revisited","heading":"7.5 Applying and interpreting lm()","text":"lm() function applied periwinkle example follows:Printing mod console gives us estimated model parameters (coefficients):first group season Spring first group species Littorina breviculaso \\(\\beta_{0}\\) mean L.brevicula spring, 56.48.\\(\\beta_{1}\\) coefficient labelled seasonSummer means variable season takes value Summer, \\(\\beta_{1}\\) must added \\(\\beta_{0}\\) - mean L.brevicula summer \\(\\beta_{0}+\\beta_{1}\\) = 56.48 \\(+\\) 16.44 \\(=\\) 72.92.\ncoefficient labelled speciesLittorina littorea \\(\\beta_{2}\\). species becomes Littorina littorea, \\(\\beta_{1}\\) must added \\(\\beta_{0}\\) thus mean L.littorea spring \\(\\beta_{0}+\\beta_{2}\\) = 56.48 \\(+\\) 7.28 \\(=\\) 63.76.season becomes Summer species becomes Littorina littorea expect effect \\(\\beta_{0}+\\beta_{1}+\\beta_{2}\\). coefficient labelled seasonSummer:speciesLittorina littorea, \\(\\beta_{3}\\) effect additional sum. interaction occurs combined effect two variables differs just adding independent effects. mean L.littorea summer \\(\\beta_{0}+\\beta_{1}+\\beta_{2}+\\beta_{3}\\) = 56.48 \\(+\\) 16.44 \\(+\\) 7.28 \\(+\\) -10.76 \\(=\\) 69.44.information including statistical tests model parameters obtained using summary():Coefficients table gives estimated \\(\\beta_{0}\\), \\(\\beta_{1}\\), \\(\\beta_{2}\\) \\(\\beta_{3}\\) along standard errors tests whether estimates differ zero.estimated mean L.brevicula spring 56.48 \\(\\pm\\) 2.187 differs significantly zero (\\(p\\) < 0.001). estimated difference L.brevicula spring L.brevicula summer 16.44 \\(\\pm\\) 3.093 also differs significantly zero (\\(p\\) < 0.001).estimated difference L.brevicula spring L.littorea spring, 7.28 \\(\\pm\\) 3.093 differs significantly zero (\\(p\\) = 0.021).proportion variance parasite load explained model 0.252 significant proportion variance (\\(p\\) < 0.001).fitting three parameters addition intercept means p-value model, p-values \\(\\beta\\) parameters, differ. also true one-way ANOVA.Replacing terms shown Figure 7.2 values example gives us 7.3.\nFigure 7.3: annotated model values parasite load preiwinkle example. measured response values pink predictions green. estimated model parameters indicated: \\(\\beta_{0}\\), mean L.brevicula spring, 56.48; \\(\\beta_{1}\\) 16.44 thus mean L.brevicula summer 56.48 + 16.44 = 72.92; \\(\\beta_{2}\\) 7.28 thus mean L.littorea spring 56.48 + 7.28 = 72.92; L.littorea summer \\(\\beta_{0}+\\beta_{1}+\\beta_{2}+\\beta_{3}\\) = 56.48 \\(+\\) 16.44 \\(+\\) 7.28 \\(+\\) -10.76 \\(=\\) 69.44. Compare Figure 7.2.\n","code":"\nmod <- lm(data = periwinkle, para ~ season * species)\nmod\n# \n# Call:\n# lm(formula = para ~ season * species, data = periwinkle)\n# \n# Coefficients:\n#                            (Intercept)                            seasonSummer  \n#                                  56.48                                   16.44  \n#              speciesLittorina littorea  seasonSummer:speciesLittorina littorea  \n#                                   7.28                                  -10.76\nsummary(mod)\n# \n# Call:\n# lm(formula = para ~ season * species, data = periwinkle)\n# \n# Residuals:\n#    Min     1Q Median     3Q    Max \n# -20.76  -6.13  -1.10   8.12  28.08 \n# \n# Coefficients:\n#                                        Estimate Std. Error t value\n# (Intercept)                               56.48       2.19   25.83\n# seasonSummer                              16.44       3.09    5.32\n# speciesLittorina littorea                  7.28       3.09    2.35\n# seasonSummer:speciesLittorina littorea   -10.76       4.37   -2.46\n#                                                    Pr(>|t|)    \n# (Intercept)                            < 0.0000000000000002 ***\n# seasonSummer                                     0.00000069 ***\n# speciesLittorina littorea                             0.021 *  \n# seasonSummer:speciesLittorina littorea                0.016 *  \n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# \n# Residual standard error: 10.9 on 96 degrees of freedom\n# Multiple R-squared:  0.252,   Adjusted R-squared:  0.229 \n# F-statistic: 10.8 on 3 and 96 DF,  p-value: 0.00000355"},{"path":"two-way-anova-revisit.html","id":"getting-predictions-from-the-model-3","chapter":"7 Two-way ANOVA revisited","heading":"7.6 Getting predictions from the model","text":"already predictions possible combinations values explanatory variables categorical.However, code using predict included , previous two chapters chapter, make easier understand complex examples later. need create dataframe values want predictions pass argument predict() function.create dataframe one column species values one column season values:Remember! variable values exactly match model., get predicted parasite load four groups:","code":"\npredict_for <- data.frame(species = rep(c(\"Littorina brevicula\", \"Littorina littorea\"), each = 2),\n                          season = rep(c(\"Spring\", \"Summer\"), times = 2))\npredict_for$pred <- predict(mod, newdata = predict_for)"},{"path":"two-way-anova-revisit.html","id":"checking-assumptions-4","chapter":"7 Two-way ANOVA revisited","heading":"7.7 Checking assumptions","text":"two assumptions model can checked using diagnostic plots. Q-Q plot obtained :Let’s look Residuals vs Fitted plot:residuals equally spread around horizontal line; assumptions seem met.","code":"\nplot(mod, which = 2)\nplot(mod, which = 1)"},{"path":"two-way-anova-revisit.html","id":"post-hoc-testing-for-lm-1","chapter":"7 Two-way ANOVA revisited","heading":"7.8 Post-hoc testing for lm()","text":"TukeyHSD() requires output aov() use lsmeans() (Least-Squares means) function lsmeans package (Lenth 2016) pairs() multcompView package. two functions can applied lm() glm() outputs.Load packages:run post-hoc test:correction multiple testing uses Tukey method (just like TukeyHSD()).results using TukeyHSD() done tests using different function.","code":"\nlibrary(lsmeans)\nlibrary(multcompView)\nlsmeans(mod, ~ species) %>%\n  pairs()\n#  contrast                                 estimate   SE df t.ratio p.value\n#  Littorina brevicula - Littorina littorea     -1.9 2.19 96  -0.869  0.3870\n# \n# Results are averaged over the levels of: season"},{"path":"two-way-anova-revisit.html","id":"creating-a-figure-3","chapter":"7 Two-way ANOVA revisited","heading":"7.9 Creating a figure","text":"","code":"\n# palette\n# blue, pink, green triadic\npal4 <- c(\"#256c7a\", \"#7a256c\", \"#6c7a25\")\n\nggplot() +\n  geom_point(data = periwinkle, aes(x = season,\n                                    y = para,\n                                    colour = species),\n             position = position_jitterdodge(dodge.width = 1,\n                                             jitter.width = 0.4,\n                                             jitter.height = 0),\n             size = 2) +\n  geom_errorbar(data = peri_summary, \n                aes(x = season, ymin = mean - se, ymax = mean + se, group = species),\n                width = 0.4, size = 1,\n                position = position_dodge(width = 1)) +\n  geom_errorbar(data = peri_summary, \n                aes(x = season, ymin = mean, ymax = mean, group = species),\n                width = 0.3, size = 1,\n                position = position_dodge(width = 1) ) +\n  scale_x_discrete(name = \"Season\") +\n  scale_y_continuous(name = \"Number of parasites\",\n                     expand = c(0, 0),\n                     limits = c(0, 128)) +\n  scale_colour_manual(values = pal4[1:2],\n                      labels = c(bquote(italic(\"L.brevicula\")),\n                                 bquote(italic(\"L.littorea\")))) +\n  # Spring:Littorina brevicula-Summer:Littorina littorea *\n  annotate(\"segment\", \n           x = 1.25, xend = 1.75, \n           y = 110, yend = 110,\n           colour = \"black\") +\n  annotate(\"segment\", \n           x = 1.25, xend = 1.25,\n           y = 110, yend = 105,\n           colour = \"black\") +\n  annotate(\"segment\", \n           x = 1.75, xend = 1.75,\n           y = 110, yend = 105,\n           colour = \"black\") +\n  annotate(\"text\", \n           x = 1.5,  y = 112,\n           label = \"***\", size = 6) +\n  # Summer:Littorina brevicula-Spring:Littorina littorea: ***\n  annotate(\"segment\", \n           x = 1.25, xend = 0.75,\n           y = 90, yend = 90,\n           colour = \"black\") +\n  annotate(\"segment\", \n           x = 1.25, xend = 1.25,\n           y = 90, yend = 85,\n           colour = \"black\") +\n  annotate(\"segment\", \n           x = 0.75, xend = 0.75,\n           y = 90, yend = 85,\n           colour = \"black\") +\n  annotate(\"text\", x = 1,  y = 92,\n           label = \"*\", size = 6) +\n# Summer:Littorina littorea-Spring:Littorina littorea: ***\n  annotate(\"segment\",\n           x = 0.75, xend = 1.75,\n           y = 120, yend = 120,\n           colour = \"black\") +\n  annotate(\"segment\",\n           x = 0.75, xend = 0.75,\n           y = 120, yend = 115,\n           colour = \"black\") +\n  annotate(\"segment\",\n           x = 1.75, xend = 1.75,\n           y = 120, yend = 115,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.25,  y = 123,\n           label = \"***\", size = 6) +\n  theme_classic() +\n  theme(legend.title = element_blank(),\n        legend.position = c(0.85, 0.98)) "},{"path":"two-way-anova-revisit.html","id":"reporting-the-results-3","chapter":"7 Two-way ANOVA revisited","heading":"7.10 Reporting the results","text":"addSee figure 7.4.\nFigure 7.4: effect season parasite load two species periwinkle. Error bars \\(\\pm 1 S.E.\\). *** significant difference \\(p < 0.001\\) level, ** \\(p < 0.01\\) level * \\(p < 0.05\\) level.\n","code":""},{"path":"summary.html","id":"summary","chapter":"8 Summary","heading":"8 Summary","text":"models common: Responses must independent\nkey pointswhere go next","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
