<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 2 What are General Linear Models | gist-lm: Get Introductory Statistical Tests as Linear models: A guide for R users</title>
<meta name="author" content="Emma Rand">
<meta name="description" content="2.1 Overview A general linear model describes a continuous response variable as a function of one or more explanatory variables. For a single explanatory variable, the model is: \[\begin{equation}...">
<meta name="generator" content="bookdown 0.24.1 with bs4_book()">
<meta property="og:title" content="Chapter 2 What are General Linear Models | gist-lm: Get Introductory Statistical Tests as Linear models: A guide for R users">
<meta property="og:type" content="book">
<meta property="og:url" content="https://3mmarand.github.io/gist-lm/what-are-linear-models.html">
<meta property="og:image" content="https://3mmarand.github.io/gist-lm/images/hex-s.png">
<meta property="og:description" content="2.1 Overview A general linear model describes a continuous response variable as a function of one or more explanatory variables. For a single explanatory variable, the model is: \[\begin{equation}...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 2 What are General Linear Models | gist-lm: Get Introductory Statistical Tests as Linear models: A guide for R users">
<meta name="twitter:site" content="@er13_r">
<meta name="twitter:description" content="2.1 Overview A general linear model describes a continuous response variable as a function of one or more explanatory variables. For a single explanatory variable, the model is: \[\begin{equation}...">
<meta name="twitter:image" content="https://3mmarand.github.io/gist-lm/images/hex-s.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11.1/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0/transition.js"></script><script src="libs/bs3compat-0.3.0/tabs.js"></script><script src="libs/bs3compat-0.3.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet">
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-115082821-1"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-115082821-1');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="assets/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">gist-lm: Get Introductory Statistical Tests as Linear models: A guide for R users</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome!</a></li>
<li class="book-part">INTRODUCTION</li>
<li><a class="" href="revision.html"><span class="header-section-number">1</span> Revision of your Introductory class</a></li>
<li><a class="active" href="what-are-linear-models.html"><span class="header-section-number">2</span> What are General Linear Models</a></li>
<li><a class="" href="terminolgy.html"><span class="header-section-number">3</span> Terminolgy</a></li>
<li class="book-part">USING lm() FOR FAMILIAR TESTS</li>
<li><a class="" href="single-regression.html"><span class="header-section-number">4</span> Single linear regression</a></li>
<li><a class="" href="t-tests-revisit.html"><span class="header-section-number">5</span> t-tests revisited</a></li>
<li><a class="" href="one-way-anova-revisit.html"><span class="header-section-number">6</span> One-way ANOVA revisited</a></li>
<li><a class="" href="two-way-anova-revisit.html"><span class="header-section-number">7</span> Two-way ANOVA revisited</a></li>
<li><a class="" href="summary.html"><span class="header-section-number">8</span> Summary</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/3mmaRand/gist-lm">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="what-are-linear-models" class="section level1" number="2">
<h1>
<span class="header-section-number">2</span> What are General Linear Models<a class="anchor" aria-label="anchor" href="#what-are-linear-models"><i class="fas fa-link"></i></a>
</h1>
<div id="overview" class="section level2" number="2.1">
<h2>
<span class="header-section-number">2.1</span> Overview<a class="anchor" aria-label="anchor" href="#overview"><i class="fas fa-link"></i></a>
</h2>
<p>A general linear model describes a continuous response variable as a function of one or more explanatory variables.
For a single explanatory variable, the model is:</p>
<p><span class="math display" id="eq:lm1">\[\begin{equation}
E(y_{i})=\beta_{0}+\beta_{1}X1_{i}
\tag{2.1}
\end{equation}\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(y\)</span> is the response variable and <span class="math inline">\(X1\)</span> is the explanatory variable.<br>
</li>
<li>
<span class="math inline">\(i\)</span> is the index of the values so <span class="math inline">\(X1_{i}\)</span> is the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(X1\)</span>
</li>
<li>
<span class="math inline">\(E(y_{i})\)</span> is the expected value of <span class="math inline">\(y\)</span> for the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(X1\)</span>.</li>
<li>
<span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> are the coefficients - or parameters - in the model. In a single linear regression, <span class="math inline">\(\beta_{0}\)</span> is often called the intercept and <span class="math inline">\(\beta_{1}\)</span> the slope.</li>
</ul>
<p>The equation <a href="what-are-linear-models.html#eq:lm1">(2.1)</a> allows the response, <span class="math inline">\(y\)</span>, to be predicted for a given value of the explanatory variable.</p>
<p>Let’s unpack what we mean by <span class="math inline">\(E(y_{i})\)</span>, the expected value of <span class="math inline">\(y\)</span>. If you measure the response for a particular value of <span class="math inline">\(x\)</span> very many times there would be some distribution of those responses. In the general linear model that distribution is assumed to be normal and its mean is the expected value for <span class="math inline">\(y\)</span>, <span class="math inline">\(E(y_{i})\)</span>.</p>
<p>Another way of saying that is that in a general linear model, we “model the mean of the response.” That the measured response is drawn from normal distribution with a mean of <span class="math inline">\(E(y_{i})\)</span> is a defining feature of the general linear model.</p>
<p>An additional assumption is that those normal distributions have the same variance for all the <span class="math inline">\(x\)</span> values.</p>
</div>
<div id="model-fitting" class="section level2" number="2.2">
<h2>
<span class="header-section-number">2.2</span> Model fitting<a class="anchor" aria-label="anchor" href="#model-fitting"><i class="fas fa-link"></i></a>
</h2>
<p>The process of estimating the model coefficients from your data (set of chosen <span class="math inline">\(X1\)</span> with their measured <span class="math inline">\(y\)</span> values) is known as <em>fitting a linear model</em>. The coefficients are also known as parameters.</p>
<p>The measured response values in your data, <span class="math inline">\(y_{i}\)</span>, will differ from the predicted values, <span class="math inline">\(\hat{y}\)</span>, randomly and these random differences are known as <em>residuals</em> or <em>errors</em>. Our parameter values are chosen to minimise the sum of the squared residuals. A very commonly used abbreviation for the sum of the squared residuals (or errors) is <span class="math inline">\(SSE\)</span>.</p>
<p><span class="math display" id="eq:sse">\[\begin{equation}
SSE = \sum(y_{i}-\hat{y})^2
\tag{2.2}
\end{equation}\]</span></p>
<p>Since the coefficient values are those that minimise the <span class="math inline">\(SSE\)</span>, those values are known as <em>least squares estimates</em>. The mean of a sample is also a least squares estimate -</p>
<p>The role played by <span class="math inline">\(SSE\)</span> in estimating our parameters means that it is also used in determining how well our model fits our data. Our model can be considered useful if its predictions are close to the observed data and the smaller the value of <span class="math inline">\(SSE\)</span>, the better the fit. In other words, there is little random variance left over in the response.
The absolute value of <span class="math inline">\(SSE\)</span> will depend on the size of the <span class="math inline">\(y\)</span> values and the sample size so it would be difficult to compare two models. Instead, we express it as a proportion of the total variation in <span class="math inline">\(y\)</span>, <span class="math inline">\(SST\)</span>:</p>
<p><span class="math display" id="eq:rsq1">\[\begin{equation}
SSE / SST
\tag{2.3}
\end{equation}\]</span></p>
<p>This is the proportion of variance left over after the model fitting. The proportion of variance explained by the model is a very commonly used metric of model fit and you have probably heard of it - R-squared, <span class="math inline">\(R^2\)</span>. It is:</p>
<p><span class="math display" id="eq:rsq1">\[\begin{equation}
R^2=1-\frac{SSE}{SST}
\tag{2.3}
\end{equation}\]</span></p>
<p>If there were no explanatory variables, the value we would predict for the response variable is its mean. Thus a good model should fit the response better than the mean. The output of <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> includes the <span class="math inline">\(R^2\)</span>. It represents the proportional improvement in the predictions from the regression model relative to the mean model. It ranges from zero, the model is no better than the mean, to 1, the predictions are perfect. See Figure <a href="what-are-linear-models.html#fig:lm-fit">2.1</a>.</p>

<div class="figure" style="text-align: left">
<span style="display:block;" id="fig:lm-fit"></span>
<img src="images/lm_fit.svg" alt="A linear model with different fits. A) the model is a poor fit - the explanatory variable is no better than the response mean for predicting the response. B) the model is good fit - the explanatory variable explains a high proportion of the variance in the response. C) the model is a perfect fit - the response can be predicted perfectly from the explanatory variable. Measured response values are in pink, the predictions are in green and the dashed blue line gives the mean of the response." width="100%"><p class="caption">
Figure 2.1: A linear model with different fits. A) the model is a poor fit - the explanatory variable is no better than the response mean for predicting the response. B) the model is good fit - the explanatory variable explains a high proportion of the variance in the response. C) the model is a perfect fit - the response can be predicted perfectly from the explanatory variable. Measured <span style=" font-weight: bold;    color: #d264c0 !important;">response values are in pink</span>, the <span style=" font-weight: bold;    color: #c0d264 !important;">predictions are in green</span> and the <span style=" font-weight: bold;    color: #64c0d2 !important;">dashed blue line gives the mean of the response</span>.
</p>
</div>
<p>Since the distribution of the responses for a given <span class="math inline">\(x\)</span> is assumed to be normal and the variances of those distributions are assumed to be homogeneous, both are also true of the residuals. It is our examination of the residuals which allows us to evaluate whether the assumptions are met.</p>
<p>See Figure <a href="what-are-linear-models.html#fig:lm-annotated">2.2</a> for a graphical representation of linear modelling terms introduced so far. We will reference this figure in later chapters.</p>

<div class="figure" style="text-align: left">
<span style="display:block;" id="fig:lm-annotated"></span>
<img src="images/generic_lm.svg" alt="A general linear model annotated with the terms used in modelling. The measured response values are in pink, the predictions are in green, and the differences between these, known as the residuals, are in blue. The estimated model parameters, \(\beta_{0}\) (the intercept) and \(\beta_{1}\) (the slope) are indicated." width="80%"><p class="caption">
Figure 2.2: A general linear model annotated with the terms used in modelling. The measured <span style=" font-weight: bold;    color: #d264c0 !important;">response values are in pink</span>, the <span style=" font-weight: bold;    color: #c0d264 !important;">predictions are in green</span>, and the differences between these, known as the <span style=" font-weight: bold;    color: #64c0d2 !important;">residuals, are in blue</span>. The estimated model parameters, <span class="math inline">\(\beta_{0}\)</span> (the intercept) and <span class="math inline">\(\beta_{1}\)</span> (the slope) are indicated.
</p>
</div>
</div>
<div id="more-than-one-explanatory-variable" class="section level2" number="2.3">
<h2>
<span class="header-section-number">2.3</span> More than one explanatory variable<a class="anchor" aria-label="anchor" href="#more-than-one-explanatory-variable"><i class="fas fa-link"></i></a>
</h2>
<p>When you have more than one explanatory variable these are given as <span class="math inline">\(X2\)</span>, <span class="math inline">\(X3\)</span> and so on up to the <span class="math inline">\(p\)</span>th explanatory variable. Each explanatory variable has its own <span class="math inline">\(\beta\)</span> coefficient.</p>
<p>The general form of the model is:
<span class="math display" id="eq:lm2">\[\begin{equation}
E(y_{i})=\beta_{0}+\beta_{1}X1_{i}+\beta_{2}X2_{i}+...+\beta_{p}Xp_{i}
\tag{2.4}
\end{equation}\]</span></p>
<p>The model has only one intercept which is the value of the response when all the explanatory variables are zero.</p>
<p>There is one problem with <span class="math inline">\(R^2\)</span> as a measure of model fit: the more explanatory variables that are added, the higher the <span class="math inline">\(R^2\)</span>. This is true even if the added variables explain a really tiny amount of the variance in the response. Using <span class="math inline">\(R^2\)</span> to select a model would mean always choosing the model with the most variables in it.
However, a key aim of statistical modelling is to understand the response and this is easier for simpler models. We want to find a balance between the complexity of the model and its explanatory power. The Adjusted <span class="math inline">\(R^2\)</span> is a way to achieve this. It reduces the <span class="math inline">\(R^2\)</span> for each coefficient added.</p>
<p>A related reason for not including variables that explain only tiny amounts of variance is overfitting. Overfitting occurs when your model fits your data very well but does not generalise. We want models that would predict the response equally well for a new set of data.</p>
</div>
<div id="general-linear-models-in-r" class="section level2" number="2.4">
<h2>
<span class="header-section-number">2.4</span> General linear models in R<a class="anchor" aria-label="anchor" href="#general-linear-models-in-r"><i class="fas fa-link"></i></a>
</h2>
<div id="building-and-viewing" class="section level3" number="2.4.1">
<h3>
<span class="header-section-number">2.4.1</span> Building and viewing<a class="anchor" aria-label="anchor" href="#building-and-viewing"><i class="fas fa-link"></i></a>
</h3>
<p><em>T</em>-tests and ANOVA, like regression, can be carried out with the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function in R. It uses the same method for specifying the model. When you have one explanatory variable the command is:</p>
<p><code>lm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory</em>)</code></p>
<p>The <code>response ~ explanatory</code> part is known as the model <strong>formula</strong>.</p>
<p>When you have two explanatory variable we add the second explanatory variable to the formula using a <code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code> or a <code><a href="https://rdrr.io/r/base/Arithmetic.html">*</a></code>. The command is:</p>
<p><code>lm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory1</em> + <em>explanatory2</em>)</code></p>
<p>or</p>
<p><code>lm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory1</em> * <em>explanatory2</em>)</code></p>
<p>A model with <code>explanatory1 + explanatory2</code> considers the effects of the two variables independently. A model with <code>explanatory1 * explanatory2</code> considers the effects of the two variables <em>and</em> any interaction between them.</p>
<p>We usually assign the output of <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> commands to an object and view it with <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code>. The typical workflow would be:</p>
<p><code>
mod &lt;- lm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory</em>)<br>
summary(mod)
</code></p>
<p>There are two sorts of statistical tests in the output of <code><a href="https://rdrr.io/r/base/summary.html">summary(mod)</a></code>: tests of whether each coefficient is significantly different from zero; and an <em>F</em>-test of the model overall.</p>
<p>The <em>F</em>-test in the last line of the output indicates whether the relationship modelled between the response and the set of explanatory variables is statistically significant.</p>
<div class="key">
<p><code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> can be used to perform tests using the General Linear Model including <em>t</em>-tests, ANOVA and regression for response variables which are normally distributed.</p>
</div>
<p>Elements of the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> object include the estimated coefficients, the predicted values and the residuals. These can be accessed with <code>mod$coeffients</code>, <code>mod$fitted.values</code> and <code>mod$residuals</code> respectively.</p>
</div>
<div id="getting-predictions" class="section level3" number="2.4.2">
<h3>
<span class="header-section-number">2.4.2</span> Getting predictions<a class="anchor" aria-label="anchor" href="#getting-predictions"><i class="fas fa-link"></i></a>
</h3>
<p><code>mod$fitted.values</code> gives the predicted values for the explanatory variable values actually used in the experiment, <em>i.e.</em>, there is a prediction for each row of data. To get predictions for a different set of values we need to make a dataframe of the different set of values and use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function. The typical workflow would be:</p>
<p><code>
predict_for &lt;- data.frame(<em>explanatory</em> = <em>values</em>)<br>
predict_for$pred &lt;- predict(mod, newdata = predict_for)
</code></p>
</div>
<div id="checking-assumptions" class="section level3" number="2.4.3">
<h3>
<span class="header-section-number">2.4.3</span> Checking assumptions<a class="anchor" aria-label="anchor" href="#checking-assumptions"><i class="fas fa-link"></i></a>
</h3>
<p>The assumptions of the model are checked using the <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> function which produces diagnostic plots to explore the distribution of the residuals. They are not proof of the assumptions being met but allow us to quickly determine if the assumptions are plausible, and if not, how the assumptions are violated and what data points contribute to the violation.</p>
<p>The two plots which are most useful are the “Q-Q” plot (plot 2) and the “Residuals vs Fitted” plot (plot 1). These are given as values to the <code>which</code> argument of <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code>.</p>
<div id="the-q-q-plot" class="section level4" number="2.4.3.1">
<h4>
<span class="header-section-number">2.4.3.1</span> The Q-Q plot<a class="anchor" aria-label="anchor" href="#the-q-q-plot"><i class="fas fa-link"></i></a>
</h4>
<p>The Q-Q plot is a scatterplot of the residuals (standardised to a mean of zero and a standard deviation of 1) against what is expected if the residuals are normally distributed.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod</span>, which <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="what-are-linear-models_files/figure-html/unnamed-chunk-2-1.png" width="60%" style="display: block; margin: auto auto auto 0;"></div>
<p>The points should fall roughly on the line if the residuals are normally distributed. In the example above, the residuals appear normally distributed.</p>
<div class="inline-figure">The following are two examples in which the residuals are not normally distributed.
<img src="what-are-linear-models_files/figure-html/unnamed-chunk-3-1.png" width="60%" style="display: block; margin: auto auto auto 0;">
</div>
<p>If you see patterns like these you should find an alternative to a general linear model such as a non-parametric test or a generalised linear model. Sometimes, applying a transformation to the response variable will result in better meeting the assumptions.</p>
</div>
<div id="the-residuals-vs-fitted-plot" class="section level4" number="2.4.3.2">
<h4>
<span class="header-section-number">2.4.3.2</span> The Residuals vs Fitted plot<a class="anchor" aria-label="anchor" href="#the-residuals-vs-fitted-plot"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-figure"><img src="what-are-linear-models_files/figure-html/unnamed-chunk-4-1.png" width="60%" style="display: block; margin: auto auto auto 0;"></div>
<p>The Residuals vs Fitted plot shows if residuals have homogeneous variance or non-linear patterns. Non-linear relationships between explanatory variables and the response will usually show in this plot if the model does not capture the non-linear relationship. For the assumptions to be met, the residuals should be equally spread around a horizontal line as they are here:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="what-are-linear-models_files/figure-html/unnamed-chunk-5-1.png" width="60%" style="display: block; margin: auto auto auto 0;"></div>
<p>The following are two examples in which the residuals do not have homogeneous variance and display non-linear patterns.
<img src="what-are-linear-models_files/figure-html/unnamed-chunk-6-1.png" width="60%" style="display: block; margin: auto auto auto 0;"><img src="what-are-linear-models_files/figure-html/unnamed-chunk-6-2.png" width="60%" style="display: block; margin: auto auto auto 0;"></p>
</div>
</div>
</div>
<div id="reporting" class="section level2" number="2.5">
<h2>
<span class="header-section-number">2.5</span> Reporting<a class="anchor" aria-label="anchor" href="#reporting"><i class="fas fa-link"></i></a>
</h2>
<p>The important information to include when reporting the results of fitting a linear model are the most notable predictions and the significance, direction and magnitude of effects. You need to ensure your reader will understand what the data are saying even if all the numbers and statistical information was removed. For example, that <span class="math inline">\(A\)</span> is much bigger than <span class="math inline">\(B\)</span> or variable <span class="math inline">\(Y\)</span> is influenced by variables <span class="math inline">\(X1\)</span> (a lot) and <span class="math inline">\(X2\)</span> (less so).
In relatively simple models, reporting group means or a slope, and statistical test information is enough. In more complex models with many variables is it common to give all the estimated model coefficients in a table.</p>
<p>In addition, your figure should show both the data and the model. This is honest and allows your interpretation to be evaluated.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="revision.html"><span class="header-section-number">1</span> Revision of your Introductory class</a></div>
<div class="next"><a href="terminolgy.html"><span class="header-section-number">3</span> Terminolgy</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#what-are-linear-models"><span class="header-section-number">2</span> What are General Linear Models</a></li>
<li><a class="nav-link" href="#overview"><span class="header-section-number">2.1</span> Overview</a></li>
<li><a class="nav-link" href="#model-fitting"><span class="header-section-number">2.2</span> Model fitting</a></li>
<li><a class="nav-link" href="#more-than-one-explanatory-variable"><span class="header-section-number">2.3</span> More than one explanatory variable</a></li>
<li>
<a class="nav-link" href="#general-linear-models-in-r"><span class="header-section-number">2.4</span> General linear models in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#building-and-viewing"><span class="header-section-number">2.4.1</span> Building and viewing</a></li>
<li><a class="nav-link" href="#getting-predictions"><span class="header-section-number">2.4.2</span> Getting predictions</a></li>
<li><a class="nav-link" href="#checking-assumptions"><span class="header-section-number">2.4.3</span> Checking assumptions</a></li>
</ul>
</li>
<li><a class="nav-link" href="#reporting"><span class="header-section-number">2.5</span> Reporting</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/3mmaRand/gist-lm/blob/master/what-are-linear-models.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/3mmaRand/gist-lm/edit/master/what-are-linear-models.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>gist-lm: Get Introductory Statistical Tests as Linear models: A guide for R users</strong>" was written by Emma Rand. It was last built on September 2021.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
